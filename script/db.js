const mysql = require('mysql2/promise');
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

// --- é…ç½®åŒº ---
const MYSQL_CONFIG = {
  host: 'nginx.naxi.fun',
  port: 13306,
  user: 'root',
  password: 'xang1057516363',
  database: 'listen-world'
};

const D1_DATABASE_NAME = 'DB';
const TABLE_NAME = 'countries';
const BATCH_SIZE = 15000;      // æ¯æ¬¡ä» MySQL å–å‡ºçš„æ€»é‡
const MAX_SQL_SIZE = 85000;   // å•ä¸ª INSERT è¯­å¥çš„æœ€å¤§å­—èŠ‚æ•° (D1 é™åˆ¶ 100KBï¼Œé¢„ç•™ç©ºé—´)

async function runMigration() {
  const connection = await mysql.createConnection(MYSQL_CONFIG);
  console.log('âœ… å·²è¿æ¥åˆ° MySQL');

  try {
    const [countResult] = await connection.execute(`SELECT COUNT(*) as total FROM ${TABLE_NAME}`);
    const totalRows = countResult[0].total;
    console.log(`ğŸ“Š æ€»è®¡ ${totalRows} æ¡æ•°æ®å¾…è¿ç§»`);

    for (let offset = 0; offset < totalRows; offset += BATCH_SIZE) {
      const [rows] = await connection.execute(
        `SELECT * FROM ${TABLE_NAME} LIMIT ${BATCH_SIZE} OFFSET ${offset}`
      );

      if (rows.length === 0) continue;

      const columns = Object.keys(rows[0]).map(col => `"${col}"`).join(', ');
      const insertHeader = `INSERT INTO ${TABLE_NAME} (${columns}) VALUES `;

      let finalSqlFileContent = "";
      let currentInsertValues = [];
      let currentSqlSize = 0;

      for (const row of rows) {
        // å°†å•è¡Œè½¬æ¢ä¸º SQL ç‰‡æ®µ
        const valArray = Object.values(row).map(val => {
          if (val === null) return 'NULL';
          if (typeof val === 'number') return val;
          return `'${String(val).replace(/'/g, "''")}'`;
        });
        const rowSql = `(${valArray.join(', ')})`;

        // è®¡ç®—å¢åŠ è¿™ä¸€è¡Œåçš„é•¿åº¦ (rowSql + é€—å· + æ¢è¡Œ)
        const rowSize = Buffer.byteLength(rowSql, 'utf8') + 2;

        // æ£€æŸ¥ï¼šå¦‚æœåŠ ä¸Šè¿™ä¸€è¡Œä¼šè¶…è¿‡é™åˆ¶ï¼Œæˆ–è€…è¿™ä¸€è¡Œæœ¬èº«å°±è¶…å¤§
        if (currentSqlSize + rowSize > MAX_SQL_SIZE && currentInsertValues.length > 0) {
          // å°å­˜å½“å‰çš„ INSERT è¯­å¥
          finalSqlFileContent += insertHeader + currentInsertValues.join(',\n') + ';\n';
          // é‡ç½®è®¡æ•°å™¨
          currentInsertValues = [];
          currentSqlSize = 0;
        }

        currentInsertValues.push(rowSql);
        currentSqlSize += rowSize;

        // æç«¯æƒ…å†µï¼šå•è¡Œå°±è¶…è¿‡äº† MAX_SQL_SIZE
        if (rowSize > MAX_SQL_SIZE) {
          console.warn(`âš ï¸ è­¦å‘Šï¼šæ£€æµ‹åˆ°ä¸€æ¡è¶…å¤§æ•°æ®è¡Œ (çº¦ ${Math.round(rowSize/1024)}KB)ï¼Œå·²å°è¯•ç‹¬ç«‹å¤„ç†ã€‚`);
        }
      }

      // å¤„ç†å‰©ä½™çš„æ•°æ®
      if (currentInsertValues.length > 0) {
        finalSqlFileContent += insertHeader + currentInsertValues.join(',\n') + ';\n';
      }

      const tempSqlFile = path.join(__dirname, 'temp_batch.sql');
      fs.writeFileSync(tempSqlFile, finalSqlFileContent);

      console.log(`ğŸš€ æ­£åœ¨æ¨é€èŒƒå›´: ${offset + 1} ~ ${offset + rows.length}...`);
      try {
        execSync(`npx wrangler d1 execute ${D1_DATABASE_NAME} --local --file=${tempSqlFile}`, { stdio: 'inherit' });
        // execSync(`npx wrangler d1 execute ${D1_DATABASE_NAME} --remote --file=${tempSqlFile}`, { stdio: 'inherit' });
      } catch (err) {
        console.error('âŒ D1 å†™å…¥å¤±è´¥ã€‚é”™è¯¯å¯èƒ½ç”±äºå•è¡Œæ•°æ®è¿‡å¤§æˆ–ç½‘ç»œé—®é¢˜ã€‚');
        return;
      }

      fs.unlinkSync(tempSqlFile);
    }

    console.log('âœ¨ è¿ç§»å®Œæˆï¼');
  } catch (error) {
    console.error('âŒ å‘ç”Ÿé”™è¯¯:', error);
  } finally {
    await connection.end();
  }
}

runMigration();
